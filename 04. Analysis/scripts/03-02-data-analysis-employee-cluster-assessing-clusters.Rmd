---
title: "Data analysis for employee cluster assessment"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: united
    highlight: tango
    code_folding: hide
params:
  author: "Ben Jaques-Leslie"
  project_number: 2312
  project_name: "Occupancy Patterns"
  google_drive_home: "G:/Shared drives/MSG Projects/1.0 Real Estate Solutions (LQ1)/2312 Work Patterns"
  data_folder_1: "prepared-data"
  data_file_1: "prep_employees_2023-05-24.rdata"
  in_number_of_clusters_start: 1
  in_number_of_clusters_end: 20
  in_seed: 27
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
tictoc::tic()
if(!("arsenal" %in% installed.packages()[,"Package"]))
{
  install.packages("arsenal")
}
if(!("oesrrr" %in% installed.packages()[,"Package"]))
{
  devtools::install_github(repo = "GSA/oesrrr")
}
library(oesrrr)
library(factoextra)
library(tidyverse)
library(janitor)
library(skimr)
library(DataExplorer)
library(readr)
library(arsenal)
library(Hmisc)
library(readxl)
library(flextable)
library(ggthemes)
library(tidymodels)
library(cluster)
```

```{r}
set.seed(params$in_seed)
```

# Data preparation {.tabset .tabset-pills}

**Project number**: `r params$project_number`

**Project name**: `r params$project_name`

**Author**: `r params$author`

**Data folder 1**: `r params$data_folder_1`

**Data file 1**: `r params$data_file_1`

**Number of clusters**: Testing `r params$in_number_of_clusters_start` to `r params$in_number_of_clusters_end`

**Random seed** `r params$in_seed`

## Load data {.tabset .tabset-pills}

Load `r params$data_file_2` from `r params$data_folder_1` data folder.

```{r}
load(file = file.path(params$google_drive_home,"03. Data Collection",params$data_folder_1,params$data_file_1))
```

Review.

```{r}
prep_employees %>% 
  skim()
```

## Functions {.tabset .tabset-pills}

### Selecting data for cluster analysis

```{r}
source(here::here("04. Analysis","scripts","select_cluster_cols.R"))
```

### Making clusters of different sizes

```{r}
source(here::here("04. Analysis","scripts","make_clusters.R"))
```

### Making clusters visualizations using PCA

```{r}
source(here::here("04. Analysis","scripts","make_fviz_clusters.R"))
```

### Creating d for cluster analysis

```{r}
source(here::here("04. Analysis","scripts","prep_employees_to_d.R"))
```

### Making clusters visualizations using PCA of different sizes, but only for `d` and adding specification

```{r}
make_fviz_clusters_d <- function(in_specification,
                            in_scale_or_rank,
                            in_working_or_observation_window,
                            in_weekday_correlation,
                            in_number_of_clusters_start,
                            in_number_of_clusters_end)
{
  make_fviz_clusters(
    in_data = d,
    in_scale_or_rank = in_scale_or_rank,
    in_working_or_observation_window = in_working_or_observation_window,
    in_weekday_correlation = in_weekday_correlation,
    in_number_of_clusters_start = in_number_of_clusters_start,
    in_number_of_clusters_end = in_number_of_clusters_end
  ) %>%
    mutate(specification = in_specification)
}
```

### Making elbow visualizations

Generates `r params$in_number_of_clusters_start` to `r params$in_number_of_clusters_end` new clusters for specifications and creates elbow charts for each specification.

```{r}
make_elbow_d <- function(in_specification,
                         in_scale_or_rank,
                         in_working_or_observation_window,
                         in_weekday_correlation, 
                         in_remove_other_statuses,
                            in_max_clusters)
{
  d %>%
    select_cluster_cols(
      in_scale_or_rank = in_scale_or_rank,
      in_working_or_observation_window = in_working_or_observation_window,
      in_weekday_correlation = in_weekday_correlation,
      in_remove_other_statuses = in_remove_other_statuses
    ) %>%
    select(where(is.numeric)) %>%
    fviz_nbclust(
      .,
      kmeans,
      k.max = in_max_clusters,
      method = "wss",
      nstart = 25,
      nboot = 10,
      # algorithm="Lloyd",
      algorithm = "MacQueen",
      iter.max = 200,
      verbose = TRUE
    ) +
    theme_fivethirtyeight() +
  labs(
    subtitle = in_specification
  )
}

```

### Making silhouette visualizations

Generates `r params$in_number_of_clusters_start` to `r params$in_number_of_clusters_end` new clusters for specifications and creates average silhouette charts for each specification.

```{r}
make_silhouette_d <- function(in_specification,
                              in_scale_or_rank,
                              in_working_or_observation_window,
                              in_weekday_correlation,
                              in_remove_other_statuses,
                            in_max_clusters)
{
  d %>%
    select_cluster_cols(
      in_scale_or_rank = in_scale_or_rank,
      in_working_or_observation_window = in_working_or_observation_window,
      in_weekday_correlation = in_weekday_correlation,
      in_remove_other_statuses = in_remove_other_statuses
    ) %>%
    select(where(is.numeric)) %>%
    fviz_nbclust(
      .,
      kmeans,
      k.max = in_max_clusters,
      method = "silhouette",
      nstart = 25,
      nboot = 10,
      # algorithm="Lloyd",
      algorithm = "MacQueen",
      iter.max = 200,
      verbose = TRUE
    ) +
    theme_fivethirtyeight() +
  labs(
    subtitle = in_specification
  )
}

```

### Making gap statistic visualizations

Generates `r params$in_number_of_clusters_start` to `r params$in_number_of_clusters_end` new clusters for specifications and creates gap statistic charts for each specification.

```{r}
make_gap_stat_d <- function(in_specification,
                            in_scale_or_rank,
                            in_working_or_observation_window,
                            in_weekday_correlation, 
                            in_remove_other_statuses,
                            in_max_clusters)
{
  d %>%
    select_cluster_cols(
      in_scale_or_rank = in_scale_or_rank,
      in_working_or_observation_window = in_working_or_observation_window,
      in_weekday_correlation = in_weekday_correlation,
      in_remove_other_statuses = in_remove_other_statuses
    ) %>%
    select(where(is.numeric)) %>%
    fviz_nbclust(
      .,
      kmeans,
      k.max = in_max_clusters,
      nstart = 25,
      method = "gap_stat",
      nboot = 10,
      # algorithm="Lloyd",
      algorithm = "MacQueen",
      iter.max = 200,
      verbose = TRUE
    ) +
    theme_fivethirtyeight() +
  labs(
    subtitle = in_specification
  )
}

```

### Making silhouette diagram visualizations[^1]

[^1]: <https://rdrr.io/cran/factoextra/man/fviz_silhouette.html>

Generates a specific number of clusters for specifications and creates silhouette diagram charts for each specification and cluster number.

```{r}
make_fviz_silhouette_d <- function(in_specification,
                            in_scale_or_rank,
                            in_working_or_observation_window,
                            in_weekday_correlation,
                            in_remove_other_statuses,
                            in_clusters)
{
  step_01 <- 
    d %>%
    select_cluster_cols(
      in_scale_or_rank = in_scale_or_rank,
      in_working_or_observation_window = in_working_or_observation_window,
      in_weekday_correlation = in_weekday_correlation,
      in_remove_other_statuses = in_remove_other_statuses
    ) %>%
    select(where(is.numeric)) 
  
  km.res <- kmeans(step_01, in_clusters, nstart = 2)
  
  sil <- silhouette(km.res$cluster, dist(step_01))
  
  fviz_silhouette(sil) +
    theme_fivethirtyeight() +
  labs(
    subtitle = in_specification
  )
}

```

## Create dataframe of all permutations {.tabset .tabset-pills}

This table shows all permutations of scaling (normalization, or rank), denominators for proportions (observation window or working days), and types of inter day correlations.

```{r}
source(here::here("04. Analysis","scripts","make_specs.R"))
```

Review data.

```{r}
specs
```

## Intra-cluster visualizations {.tabset .tabset-pills}

### Elbow

```{r}
elbows <- 
  specs %>%
   select(
    in_scale_or_rank,
    in_working_or_observation_window,
    in_weekday_correlation,
    in_specification,
    in_remove_other_statuses
  ) %>%
   mutate(
    in_max_clusters = params$in_number_of_clusters_end
    ) %>% 
  distinct() %>% 
  pmap(make_elbow_d)
```

The elbow charts below look consistent across the different specifications of clusters. Five clusters appears to be an acceptable number of clusters by this metric.

```{r}
elbows
```

### Silhouette score

```{r}
silhouette_scores <-
  specs %>%
  select(
    in_scale_or_rank,
    in_working_or_observation_window,
    in_weekday_correlation,
    in_specification,
    in_remove_other_statuses
  ) %>%
  mutate(
    in_max_clusters = params$in_number_of_clusters_end
    ) %>% 
  distinct() %>%
  slice_head(n = 4) %>%
  pmap(make_silhouette_d)
```

The mean silhouette coefficient measures how close a point in one cluster is the the points in neighboring clusters.

Mathematically this is:

$$
\frac{b-a}{max(a,b)}
$$

where $a$ is the mean distance to other points in the same cluster and $b$ is the mean nearest cluster distance[^2].

[^2]: <https://medium.com/geekculture/stop-using-the-elbow-method-96bcfbbbe9fd>

Average silhouette charts below suggest a different number of clusters than the elbow charts above. Most specifications recommend only two clusters, though three clusters are recommended for the specification where the observation window time is used to calculate percentages, the intra-workday correlations are calculated from an indicator for telework, and scaling is done by ranks.

```{r}
silhouette_scores
```

### Gap statistic

```{r}
gc()
gap_stats <- 
  specs %>%
   select(
    in_scale_or_rank,
    in_working_or_observation_window,
    in_weekday_correlation,
    in_specification,
    in_remove_other_statuses
  ) %>%
   mutate(
    in_max_clusters = params$in_number_of_clusters_end
    ) %>% 
  distinct() %>% 
  pmap(make_gap_stat_d)
```

```{r}
gap_stats
```

## Inter-cluster visaulizations {.tabset .tabset-pills}

### PCA cluster visualizations

Iterate over `specs` creating and collecting dataframe of clusters from all of the above specifications.

```{r}
pca <- 
  specs %>%
  slice_head(n = 1) %>% 
  pmap_dfr(make_fviz_clusters_d)
```

```{r}
pca %>% 
  # filter(specification == params$in_specification) %>% 
  .$fviz_cluster
```

### Silhouette diagram visualizations

```{r}
silhouette_diagrams <- 
  specs %>%
    select(
    in_scale_or_rank,
    in_working_or_observation_window,
    in_weekday_correlation,
    in_specification,
    in_remove_other_statuses
  ) %>%
  distinct() %>% 
  slice(rep(1:n(), each = params$in_number_of_clusters_end)) %>% 
  rownames_to_column(var = "temp_01") %>% 
  mutate(temp_02 = as.numeric(temp_01),
         temp_03 = temp_02/params$in_number_of_clusters_end,
         temp_04 = ceiling(temp_03),
         temp_05 = temp_04*params$in_number_of_clusters_end-params$in_number_of_clusters_end,
         temp_06 = temp_02 - temp_05) %>% 
  rename(in_clusters = temp_06) %>% 
  select(-starts_with("temp_")) %>% 
  filter(in_clusters > 1) %>% 
  # slice(2) %>%
  pmap(make_fviz_silhouette_d)
```

```{r}
silhouette_diagrams
```

## Notes {.tabset .tabset-pills}

<https://towardsdatascience.com/silhouette-method-better-than-elbow-method-to-find-optimal-clusters-378d62ff6891>

## Save data {.tabset .tabset-pills}

File name.

```{r eval=FALSE, include=FALSE}
file_name <- glue::glue("clusters-employee-{Sys.Date()}.rdata")
file_name
```

```{r eval=FALSE, include=FALSE}
save(kclusts, file = file.path(params$google_drive_home,"03. Data Collection","prepared-data",file_name))
```

Remove all data elements.

```{r eval=FALSE, include=FALSE}
rm(list = ls())
gc()
```

## Analysis time {.tabset .tabset-pills}

```{r}
tictoc::toc()
```
