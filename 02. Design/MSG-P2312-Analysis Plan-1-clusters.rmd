---
title: "Analysis plan"
# date: "`r Sys.Date()`"
output: 
  html_document:
    theme: united
    highlight: tango
    code_folding: hide
params:
  author: "Sara Guenther and Ben Jaques-Leslie"
  project_number: 2312
  project_name: "Occupancy Patterns"
  analysis_plan_title: "Phase 1 - Clusters"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(skimr)
library(DataExplorer)
library(readr)
library(oescolorrrs)
library(oesrrr)
library(flextable)
library(tidymodels)
library(ggthemes)
```

```{r}
table_n <- 0
```

#Proofread for typos

Project Name: `r params$project_name`

Project Code: `r params$project_number`

Analysis plan title: `r params$analysis_plan_title`

Date Finalized: `r nice_date(Sys.Date())`

<!-- How this document is to be used:  -->

<!-- This document serves as a basis for distinguishing between planned confirmatory analyses and any exploratory analyses that might be conducted on project data. This is crucial to ensuring that results of statistical tests are properly interpreted and reported. For the Analysis Plan to fulfill this purpose, it is essential that it be finalized and date-stamped before we take possession of outcome data. Once this plan is finalized, a date is entered above, and the document is posted publicly on our team website.  -->

<!-- If any analyses are described that will not be included in the MSG abstract or reported to the agency partner, then explicitly identify these in order to streamline reanalysis. -->

### Project Description

<!-- [Brief description of the project, including the challenge, the intervention(s) to be tested, and the questions to be answered. This should be brief, but should provide context sufficient for the analysis plan that follows.] -->

The U.S. General Services Administration's FY 2022 Annual Evaluation
Plan includes evaluation goals that involve The Future of Work projects
and objectives. This initiative is part of an effort to right-size the
federal real estate footprint. Specifically, this project will examine
the effects of distributed, virtual, and asynchronous work with the goal
of informing future changes to interior space planning and building
operations. We will join GSA telework rates and facility occupancy
patterns with GSA roster data and describe rates of telework and on site
work across employment and personal demographics. We will also determine
the rates at which teams work together onsite, remotely, or in a hybrid
environment.

### Pre Registration Details

This Analysis Plan will be posted on the GSA Evaluation Division website
at [TBD] before outcome data are analyzed. In addition, this project
will be pre registered in the [registry name] at [link to the registry,
either main page or project-specific page].

### Research Question(s)

This work will address the following research questions: 1. What are the
rates of telework since the federal return-to-office transition? 2. Do
telework behaviors match position category (e.g., onsite, offsite, etc.)
in the roster? 3. At what rates to teams work together onsite vs.
remotely? 4. Do the telework patterns of supervisors match the telework
patterns of supervisees?

At this stage, our research questions are aimed at describing patterns
of telework and federal building occupancy rather than estimating the
impacts of telework.

## Data and Data Structure

This section describes variables that will be analyzed, as well as
changes that will be made to the raw data with respect to data structure
and variables.

### Data Source(s):

We will use Daily Check-In data obtained from Management Science and
Innovation (MSI), a firm contracted to collect and maintain these data.
We will merge in additional variables from the GSA Roster obtained from
D2D. The GSA roster is updated monthly at the end of each month.

```{r}
table_n <- table_n + 1
```

#### Table `r table_n`. GSA Daily Check-In Data Variables Available Feb 2022-Dec 2022.

<!-- Table 1 and 2 could use better updating of description column -->

<!-- SSO=Staff or service office -->

<!-- Done -->

```{r}
tbl_daily_check_in <- tibble("Variable Name" = c(
  "date",
"sso",
"short_id",
"dept_id",
"employee_name",
"supervisor_name",
"location",
"daily_status",
"supervisor_correction"
)
)
```

```{r}
tbl <- 
  tbl_daily_check_in %>% 
  add_column(
    "Description" = c(
  "Date of check-in",
  # Is SSO single sign on? What did we decide?
"Staff or service office",
"2-digit department id",
"Full department id code",
"Employee name (Last, First Middle)",
"Supervisor name (Last, First Middle)",
"State abbreviation-City-Site (e.g. MA-WESTFORD-HOME and MA-BOSTON-FB Causeway St)",
"Status of the staff on that day (e.g., Teleworking, Leave, Supervisor Corrected, No Response, Reporting to Job Site, Other)",
# I think that this is an indicator for whether the supervisor corrected the record
"If daily status is Supervisor Corrected, then this is the work status entered by the supervisor"
)
)
```

```{r}
tbl %>% 
  flextable() %>% 
  # add_header_row(values = c("","","Type of analysis", "Type of analysis")) %>% 
  # set_header_labels(Group = "Level of analysis") %>% 
  merge_h(part = "header") %>% 
  merge_v(j = 1) %>% 
  theme_vanilla() %>% 
  autofit()
```

```{r}
table_n <- table_n + 1
```

#### Table `r table_n`. GSA Roster Variables.

Additional administrative data that may be useful for exploratory
analysis includes:

```{r}
tbl_roster <- tibble("Variable Name" = c("snapshot_date", "department_id", "employee_job_business_unit_description", "full_name", "employee_e_mail_address", "position_title", "pay_plan", "occupational_series", "grade", "eod_date", "supervisor_level", "supervisor_level_description", "supervisor_display_name", "supervisor_e_mail_address", "business_line_2_letter_department_id", "gsa_sso", "agency_subelement_code_description", "gsa_region", "gsa_duty_station_region", "location_city", "location_state", "duty_station_code", "employee_job_bargaining_unit_description", "employee_summary_bargaining_unit", "payroll_accounting_code", "position_number", "position_category_code", "position_category_description"
                                  # , "file_name"
)
)
```

```{r}
tbl <- 
  tbl_roster %>% 
  add_column(
"Description" = c(
 "Date of data export",
"GSA department ID",
"Business unit of the staff person",
"Employee name as Last,First Middle",
"Email address of staff",
"Position title",
"Pay plan code",
"Occupational series code",
"Position grade",
"Entry on duty i.e. staff's first day on the job",
"Supervisor status code of staff",
"Supervisor status description of staff",
"Supervisor name as First Last",
"Supervisor email address",
"First two letters of GSA department ID",
"Staff or service office code",
"Staff or service office description",
"GSA region number",
"Duty station GSA region number",
"Staff city",
"Staff state",
"Duty station number",
"Staff bargaining unit descripton",
"Staff bargaining unit number",
"Payroll accounting code",
"Position number",
"Position location category code",
"Position location category description (e.g., Onsite flexible, Offsite, Onsite required, Not specified)"
)
)
```

```{r}
tbl %>% 
  flextable() %>% 
  # add_header_row(values = c("","","Type of analysis", "Type of analysis")) %>% 
  # set_header_labels(Group = "Level of analysis") %>% 
  merge_h(part = "header") %>% 
  merge_v(j = 1) %>% 
  theme_vanilla() %>% 
  autofit()
```

### Outcomes to Be Analyzed:

<!-- [List all outcome variables for which analysis is planned. If specific variable names are unavailable, describe the outcomes in sufficient detail to appropriately guide or constrain their calculation. Specify which outcomes will be submitted to confirmatory versus exploratory analysis (or do this later in the ‘Statistical Models & Hypothesis Tests’ section if it is more appropriate there).] -->

For much of this study, no particular outcome will be analyzed. For
cluster and categorization, we will use various measures of staff work
location and frequency, for example, proportion of time teleworking or
frequency of teleworking on particular days. We will investigate the
relationships between these and other factors.

### Transformations of Data Structure:

<!-- [Describe variables that will be added to the raw data. These may be variables used in the experimental design (e.g., blocking variables) or covariates merged in from a different dataset.]  -->

<!-- [Describe new variables that will be created by transforming or combining variables in the raw data. If you plan on transforming, centering, or recoding the data, or will apply a coding scheme for categorical variables, please describe that process.  If any measurements are  going to be combined into an index (or even a mean), what measures will you use and how will they be combined? Include either a formula or a precise description of your method.] -->

<!-- [Describe any plans to transform the structure of your data (e.g., from cross-sectional to panel).] -->

<!-- Why start cohort in March? I believe because of data availability, but good to clarify in text. -->

<!-- Done -->

For all analysis, we will used a defined cohort of staff to examine work
status over period of time. A cohort of staff employed in the month of
March 2022 will be followed over six months. Teams will be defined by
the supervisors of groups of staff in the beginning of March 2022. We
are choosing March 2022 because we were told by the data providers that
earlier data was less reliable. We also wanted to have enough time to
pass to examine work patterns. March 2022 is a good start for both data
reliability and length of time to examine behavior. Any analysis we
conduct may be reproduced on a separate cohort or may be combined with
multiple cohorts depending on the data availability.

<!-- Not sure i follow the deduping logic. If two employees have the same name, then they may have different EOD Dates. But maybe there are no duplicates on full name so it’s not an issue. -->

Both data sources will be checked for duplication and deduplicated. The
daily check-in data has no true unique identifier. The roster data is
uniquely identified by `employee_e_mail_address` and `snapshot_date`, but some entries for `employee_e_mail_address` are null. 
The roster data *should not* have any duplications on
`employee_e_mail_address` and `snapshot_date`, but this will be checked.
To create a unique identifier in the daily check-in data, we will
following process:

1.  Import all months of check-in data

2.  Transform supervisor name to match format of the roster data, and create new variables for the end of the month prior to the check-in date and the end of the month of the check-in date to match the `snapshot_date`

3.  Inner join check-in and roster data  on employee name, department ID and supervisor name, and prior month, creating a new data set called `joined data 1`

4.  Remove rows in `joined data 1` from the check-in data (i.e. anti-join), then inner join check-in and roster data  on employee name, department ID and supervisor name, and current month, creating a new data set called `joined data 2`

5.  Bind row from `joined data 1` and `joined data 2`, creating a new data set called `bound data`

6.  Select the distinct employee email addresses and names from `bound data` and assign a unique identifier to this called `person_id`, creating a new data set called `unique ID`

7.  Join the `unique ID` to `bound data` on employee email addresses and names

8.  Repeat steps 5 and 6 until no new `employee_e_mail_address` entries
    are found, or no roster data is available

9.  Repeat steps 1 through 7 for all other months in observation window

10. Bind all joined data across observation window.

After this, the combined data *should* be uniquely identified by
`person_id` and `date`. The data set will contain all the
daily check-in and roster information across the observation window.

If any duplicates remain after the steps above, the general approach to
deduplication will be that categorical variables will be restructured as
indicator variables taking on a one for each category associated with
the duplicate. There appear to be no numeric variables.

The analysis will be done for staff and teams separately and aggregated
independently. Employees will be categorized. Also, employees with be grouped into teams based on supervisor. These teams will also be categorized.  The table below defines how we plan to aggregate for
staff and teams.

```{r}
table_n <- table_n + 1
```

#### Table `r table_n`. Level of analysis and aggregation

```{r, echo=FALSE}
tbl <- 
  tibble::tibble(
    # level = rep("Level of analysis",2),
                      Group = c("Staff", "Team"),
                      Aggregation = c("Person level aggregation of work status", "Team level aggregation of work status"),
                      # Sequence = c("Daily person work status", "Daily team work status")
                       )
```

```{r}
tbl %>% 
  flextable() %>% 
  # add_header_row(values = c("","","Type of analysis", "Type of analysis")) %>% 
  set_header_labels(Group = "Level of analysis") %>% 
  merge_h(part = "header") %>% 
  merge_v(j = 1) %>% 
  theme_vanilla() %>% 
  autofit()
```

<!-- [I might be more discerning about using "staff" vs. "employees" vs. "teams" vs. "groups" vs. "clusters" -- we are grouping employees into teams, but also categorizing them.]  -->

<!-- Done -->





ADD TEAM CLAFFICATION RULES FOR STAFF AND TEAM ANALYSIS

We will approach grouping staff and teams in two ways. First,
rules-based groups will be formed. For these, definitions of different
types of work will be defined. Second, groups will be formed using
k-means clustering. This unsupervised machine learning method produces a
defined number of groups (or clusters) minimizing the distance between
the members.

For both rules-based and cluster classification of individual staff, the
daily check-in data will be transformed so that each row is one staff
person. From the raw data, the following variables will be defined:

-   Proportion of days onsite

-   Proportion of days remote

-   Proportion of days remote by the day of the week

-   Correlation of work status between days of the week

-   Number of working days

-   Indicator for an exit from employment

-   Number of supervisors

-   Size of team over observation window

<!-- How are you doing team classification? Are you going to generate a team -->
<!-- ID based on some rule? If so what is it, and to the prior point, how do -->
<!-- you handle changing team composition over time? -->

Teams will be defined based on the supervisors in March 2022. The unique identifier for teams will be the `supervisor_e_mail_address`. All employees under those supervisors will be defined as part of the team. Employees may join and leave a team over the observation window.

For both rules-based and cluster classification of teams, the daily
check-in data will be transformed so that each row is one team as
defined by the supervisor. Supervisors may be in multiple teams as
supervisor and subordinate. From the raw data, the following variables
will be defined:

-   Average size of team over observation window

-   Total employees in team over observation window

-   Proportion of staff working days onsite

-   Proportion of staff working days remote

-   Proportion of staff working days remote by the day of the week

-   Proportion of days of staff concurrent remote status

-   Proportion of days of staff concurrent onsite status

-   Proportion of staff exiting team

-   Number of staff working days

### Data Exclusion and Treatment of Missing Data:

<!-- [Describe criteria you will use to determine whether any observations should be excluded from analysis (e.g., values that are likely data-recording errors, outliers, etc.).] -->

<!-- The analysis plan is a good place to define the rules for classification -->
<!-- Re: missing supervisor name and some other values. It is possible that -->
<!-- people change supervisors or departments. Do we care about this? And how -->
<!-- should we deal with it? At a minimum, maybe we want a slightly different -->
<!-- imputation like if supervisor is the same both with earlier and later -->
<!-- nonmissing observations, use that value, otherwise use prior supervisor? -->

We have no plans to exclude any data.

Missing data from the combined data in will be treated as defined in the
table below.

```{r}
table_n <- table_n + 1
```

#### Table `r table_n`. Treatment of missing data from daily check in

```{r}
tbl_combined <- 
  tbl_daily_check_in %>% 
  bind_rows(tbl_roster)
# tbl_combined
```

```{r}
tbl <- 
tbl_combined %>% 
add_column(
"Treatment if missing" = c(
  "Drop observation",
  "Joined with gsa_sso from roster data, impute from other observations of same staff",
  "Impute from other observations of same staff",
  "Joined with department_id from roster data, impute from other observations of same staff",
  "Joined with full_name from roster data, drop observation",
  "Joined with supervisor_display_name from roster data, impute from other observations of same staff",
  "Label as missing",
  "Label as missing",
  "Label as missing", "Label as missing",
  "Label as missing",
  "Label as missing",
  "Drop observation",
  "Label as missing",
"Label as missing",
"Label as missing",
"Label as missing",
"Label as missing",
"Label as missing",
"Label as missing",
"Label as missing",
"Label as missing",
"Label as missing",
"Label as missing",
"Label as missing",
"Label as missing",
"Label as missing",
"Label as missing",
"Label as missing",
"Label as missing",
"Label as missing",
"Label as missing",
"Label as missing",
"Label as missing",
"Label as missing",
"Label as missing",
"Label as missing"
)
) %>% 
  filter(!(`Variable Name` %in% c("gsa_sso","department_id","full_name","supervisor_display_name")))
```

```{r}
tbl %>% 
  flextable() %>% 
  # add_header_row(values = c("","","Type of analysis", "Type of analysis")) %>% 
  # set_header_labels(Group = "Level of analysis") %>% 
  merge_h(part = "header") %>% 
  merge_v(j = 1) %>% 
  theme_vanilla() %>% 
  autofit()
```

<!-- [Describe your plan to handle missing data.  How will you deal with incomplete or missing data (e.g., pairwise or listwise deletion, imputation, interpolation)?] -->

## Study Design and Analytic Methods

This section describes the statistical models and hypothesis tests that
will make up the analysis --- including any follow-ups on effects in the
main statistical model and any exploratory analyses that can be
anticipated prior to analysis.

### Study Design

<!-- [prompt] -->

<!-- Not sure about using percentiles for cutoffs. I would assume based on -->
<!-- classifications that more that 5 percent of teams are fully remote. For -->
<!-- individuals, i think there is more alignment on things like number of -->
<!-- days in a pay period in the office because of policy definitions for -->
<!-- people who are not remote and have to be in the office 2 days per pay -->
<!-- period. For teams maybe an extension of that basic ideas (e.g., fewer -->
<!-- than 2 days in office on average is fully remote) -->


<!-- Are all of these taking averages over the whole time period (9 months or -->
<!-- whatever)? Would we potentially want to know about things like people -->
<!-- who have more specific weekly patterns? -->

<!-- The thing that is missing here that is potentially more complicated is -->
<!-- figuring out more about how teams operate as collections of individuals. -->
<!-- For example, you could I think in this approach have a team that is 20 -->
<!-- percent average telework where everyone goes in person on Mondays and -->
<!-- the rest of the time is distributed, or you could have a team that is 20 -->
<!-- percent telework where people go in at random times and never see each -->
<!-- other. I am interested to know the extent to which people are -->
<!-- co-locating with their teams (and if some people are being left -->
<!-- out---which may help motivate some equity questions about performance -->
<!-- ratings for people who don't get face time with the boss, for example). -->
<!-- I think we are missing that level of analysis here. -->


<!-- MD: There are policy definitions of remote. 100% of days could be classified as all remote (separate rule); policy rules if you are not a full-time worker (you are a teleworker) you report two days a pay period; could align cut-offs with policy type definitions. # of days cutoff.  -->
<!-- Ben: the way I defined groups is mutually exclusive, but does not need to be that way -->
<!-- Ben: Other rules to examine -->
<!-- JB: policy side, missingness (whole groups of people missing on some dimension tells you something about data collection procedure) -->

<!-- MD: other roster data might be relevant - position category could give diff patterns for people who are analysts vs. building inspectors or supervisors vs. non supervisors, pay grade; lower pay grade less likely to have remote option -->
<!-- Ben: confusion matrix - assume that some group works in this sort of way but guess what they don’t! What is happening? -->

<!-- MD: categories: onsite flexible, onsite, remote; but not sure of levels of going in within categories. What is the average of going in? -->
<!-- MD: discretion of work patterns by regional commissioners  -->


This is a descriptive study attempting to characterize the work patterns
of GSA staff as individuals and as teams. Work patterns will be
categorized by a rules-based approach and a supervised machine learning
approach called k-means clustering.

For the rules based approach, the portion of working days remote will be
the key variable to determine what category a staff or team will be in.
Staff will be grouped as follows:

1.  **All remote** - Staff who work remotely above the 95th percentile
    <!-- could be 75th -->
2.  **Mostly remote** - Staff who work remotely between the median and
    the 95th percentile <!-- could be 75th -->
3.  **Mostly onsite** - Staff who work remotely between 5th percentile
    and the median <!-- could be 25th -->
4.  **All onsite** - Staff who work remotely below the 5th percentile
    <!-- could be 75th -->

Teams will be categorized similarly:

1.  **All remote** - Teams that work remotely above the 95th percentile
    <!-- could be 75th -->
2.  **Mostly remote** - Teams that work remotely between the median and
    the 95th percentile <!-- could be 75th -->
3.  **Mostly onsite** - Teams that work remotely between 5th percentile
    and the median <!-- could be 25th -->
4.  **All onsite** - Teams that work remotely below the 5th percentile
    <!-- could be 75th -->

For the second categorization, a k-means clustering algorithm will be
used. We follow the methods layed out in:

-   [Cluster Analysis in
    R](https://www.r-bloggers.com/2021/04/cluster-analysis-in-r/)

-   [K-means Clustering in R with
    Example](https://www.guru99.com/r-k-means-clustering.html)

-   [K-means clustering with tidy data
    principles](https://www.tidymodels.org/learn/statistics/k-means/)

For staff clusters, the following variables will be used to define the
clusters:

-   Proportion of days onsite

-   Proportion of days remote

-   Proportion of days remote by the day of the week

-   Correlation of work status between days of the week

-   Number of working days

-   Average size of team over observation window

For team clusters, the following variables will be used:

-   Averages size of team over observation window

-   Proportion of staff working days onsite

-   Proportion of staff working days remote

-   Proportion of staff working days remote by the day of the week

-   Proportion of days of staff concurrent remote status

-   Proportion of days of staff concurrent onsite status

-   Proportion of staff exiting team

-   Number of staff working days

All of the these variables will be scaled to reduce the effects of
outliers should they be present.

<!-- Why mention sq(num obs)/2 if you are not going to use that rule? -->

<!-- Removed -->

To determine the number appropriate number of clusters, several methods
exist. For this work, the *elbow method* will be used. To do this, the
k-means algorithm will be executed for different numbers of clusters
from 1 to 20. For each number of clusters, a total within sum of squares
will be calculated. As the number of number of clusters increases the
total within sum of squares will decrease. The optimal number of
clusters is when the decrease in total within sum of squares starts
tapering off.

The figure below shows an example of the this. The total within sum of
squares decreases with the number of clusters. In this example, three
clusters appears to be the point where the returns to more cluster
diminishes. We will also construct silhouette charts to confirm the
number of clusters.

#### Figure 1. Elbow method example

```{r}
set.seed(27)

centers <- tibble(
  cluster = factor(1:3), 
  num_points = c(100, 150, 50),  # number points in each cluster
  x1 = c(5, 0, -3),              # x1 coordinate of cluster center
  x2 = c(-1, 1, -2)              # x2 coordinate of cluster center
)

labelled_points <- 
  centers %>%
  mutate(
    x1 = map2(num_points, x1, rnorm),
    x2 = map2(num_points, x2, rnorm)
  ) %>% 
  select(-num_points) %>% 
  unnest(cols = c(x1, x2))

points <- 
  labelled_points %>% 
  select(-cluster)

kclusts <- 
  tibble(k = 1:20) %>%
  mutate(
    kclust = map(k, ~kmeans(points, .x)),
    tidied = map(kclust, tidy),
    glanced = map(kclust, glance),
    augmented = map(kclust, augment, points)
  )

clusters <- 
  kclusts %>%
  unnest(cols = c(tidied))

assignments <- 
  kclusts %>% 
  unnest(cols = c(augmented))

clusterings <- 
  kclusts %>%
  unnest(cols = c(glanced))

ggplot(clusterings, aes(k, tot.withinss)) +
  geom_line() +
  geom_point() +
  theme_minimal()

```

After the optimal number of clusters is determine, the clusters from
that iteration will be used to categorized the staff and team occupancy.

The work pattern statistics described below will be used to
characterized the clusters defined by the k-means algorithm.

### Statistical Models & Hypothesis Tests

<!-- [What criteria will you use to make inferences? Please describe the information you will use (e.g., specify the p-values), as well as cut-off criteria, where appropriate. Will you be using one- or two-tailed tests for each of your analyses? If you are comparing multiple conditions or testing multiple hypotheses, what method will you use to correct for multiple tests? If you are taking into account practical significance, please specify a minimum effect size of interest.] -->

This is descriptive work and we will not be making any causal claims.

### Descriptive Statistics, Tables, & Graphs

<!-- [What descriptive statistics, tables, and graphs will be needed for reporting? If possible, provide table shells and/or mock graphs. If any statistics, tables, or graphs  are listed that will not be included in the MSG abstract or reported to the agency partner, then explicitly identify these in order to streamline reanalysis.] -->

This work will address the following research questions: 1. What are the
rates of telework since the federal return-to-office transition? 2. Do
telework behaviors match position category (e.g., onsite, offsite, etc.)
in the roster? 3. At what rates to teams work together onsite vs.
remotely? 4. Do the telework patterns of supervisors match the telework
patterns of supervisees?

Three broad parts of descriptive work are part of this analysis. First,
the overall description of work patterns in the data. Then, differences
in work patterns by rules-based group, and differences in descriptive
data by those groups. Lastly, difference in k-means cluster by work
patterns and descriptive data.

The principle work pattern statistics are as follows:

-   Staff work pattern statistics:

    -   Proportion in staff time telework

    -   Proportion in staff time telework by the day of the week

    -   Proportion in staff time onsite

    -   Proportion in staff time onsite by the day of the week

    -   Correlations of by staff time between the days of the week

    -   Size of teams

    -   Number of working days

    -   Number exiting employment

    -   Number changing supervisors

-   Team work pattern statistics:

    -   Proportion in staff time telework

    -   Proportion in staff time onsite

    -   Proportion of concurrent remote days for team members

    -   Proportion of concurrent onsite days for team members

    -   Size of teams

    -   Number of staff working days

The descriptive statistics are:

-   Staff descriptive statistics

    -   Number and proportion of staff by grade

    -   Number and proportion of staff by occupational series

    -   Number and proportion of staff by position category

    -   Number and proportion of staff by GSA region

    -   Number and proportion of staff by SSO

    -   Number and proportion of staff by state

    -   Number and proportion of staff by city

    -   Number and proportion of staff by supervisor level

-   Team descriptive statistics

    -   Number and proportion of staff by most frequent grade

    -   Number and proportion of staff by most frequent occupational
        series

    -   Number and proportion of staff by most frequent position
        category

    -   Number and proportion of staff by most frequent GSA region

    -   Number and proportion of staff by most frequent SSO

    -   Number and proportion of staff by most frequent state

    -   Number and proportion of staff by most frequent city

    -   Number and proportion of staff by most frequent supervisor level

The staff statistics will be calculated for the following groups:

1.  Whole cohort of staff
2.  By rule-based categories of work pattern
3.  By cluster defined categories of work pattern

The team statistics will be calculated for the following groups:

1.  Whole cohort of teams
2.  By rule-based categories of work pattern
3.  By cluster defined categories of work pattern

To understand the relationship between staff work patterns and their
supervisor, we will calculate the proportion of the staff that fall into
the same rule-based and clusters as their supervisors overall, as well
as by the above categories.

The results will be presented in tables, and we will generate
visualizations for a subset of the results for streamlined
communication. We will use visualizations to validate the work pattern
groupings and demonstrate any deviation between clusters, rules-based
categories, and stated telework position.

### Confirmatory Analyses:

<!-- [Specify the hypothesis test(s) that will be reported as confirmatory. Which outcome and which of the above statistical models will you use to test each hypothesis? If you plan to test null hypotheses other than equality (zero effect), please specify the type of test and the margin. Remember that any test not included here must be noted as an exploratory test in any report of this research. Keep in mind that you can specify contingent or follow-up analyses that are still confirmatory. For example, if you find a main effect of the treatment, will you test for heterogeneous treatment effects? Will you look for specific pairwise differences between treatment arms if you find an overall effect of the pooled treatment? Exploratory analyses can be recorded in the next section. If any analyses are described that will not be included in the MSG abstract or reported to the agency partner, then explicitly identify these in order to streamline reanalysis.] -->

We plan no confirmatory analyses.

### Exploratory Analysis:

<!-- [OPTIONAL: If you plan to explore your data set to look for unexpected differences or relationships, you may describe those tests here. An exploratory test is any test where a prediction is not made up front, or where there are multiple possible tests that you are going to use. A statistically significant finding in an exploratory test is a great way to form a new confirmatory hypothesis, which could then be tested using a pre-specified analysis at a later time. Note that exploratory analyses will not, by default, be included in reanalysis.] -->

We plan no exploratory analyses. Though, all this work may be considered
exploratory.

### Inference Criteria, Including Any Adjustments for Multiple Comparisons:

<!-- [What criteria will you use to make inferences? Please describe the information you will use (e.g., specify the p-values), as well as cut-off criteria, where appropriate. Will you be using one- or two-tailed tests for each of your analyses? If you are comparing multiple conditions or testing multiple hypotheses, what method will you use to correct for multiple tests? If you are taking into account practical significance, please specify a minimum effect size of interest.] -->

We will not be making any inference.

### Limitations:

<!-- [Describe any anticipated limitations associated with this analysis, if not previously identified in the Project Design document.] -->

This is non causal research. The work will not demonstrate if changes or
attributes caused differences, only if there are relationships. K-means
clustering can be sensetive to the random locations of the first points
selected to calculate differences and define clusters.
